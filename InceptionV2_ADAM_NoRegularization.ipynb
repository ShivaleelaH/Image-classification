{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_ADAM_NoRegularization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGvFhrh4wS71"
      },
      "source": [
        "*   Network     : Inception v2\n",
        "*   Optimizer   : ADAM\n",
        "*   Regularizer : No regularization\n",
        "\n",
        "Ref for code: https://arxiv.org/pdf/1512.00567v3.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCplTaTGwWSy",
        "outputId": "cccb8c83-dfc5-4017-d3f8-a14d9414093a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras import callbacks\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.datasets import cifar100\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, concatenate, Dropout\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import layer_utils, data_utils, vis_utils, plot_model #data_utils.get_file #vis_utils.model_to_dot\n",
        "\n",
        "import numpy as np\n",
        "import pydot\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import SVG\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-07f2f95eb5eb>:32: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
            "Instructions for updating:\n",
            "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oArla80JwaQW",
        "outputId": "218278bb-c5bd-4897-b3bc-f6e28534f674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Loading cifar100 dataset and dividing into Train, Validation and Test sets\n",
        "\n",
        "(X_train, Y_train), (x_test, y_test_o) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_validation = keras.utils.to_categorical(y_validation, 100)\n",
        "y_test = keras.utils.to_categorical(y_test_o, 100)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcFETYCiwb7R"
      },
      "source": [
        "weight_decay = 0.0005\n",
        "num_of_classes = 100\n",
        "conv_activation_func = 'elu'\n",
        "\n",
        "l_rate = 0.0001\n",
        "batch_size = 128\n",
        "maxepoches = 40\n",
        "lr_decay = 1e-6"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvHidtzcwdas"
      },
      "source": [
        "def inceptionv2(input):\n",
        "    model = Sequential()\n",
        "\n",
        "    ##### MAIN LAYER #####\n",
        "    main = Conv2D(64, (3, 3), strides=(2,2), padding='same',activation=conv_activation_func)(input)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "\n",
        "    main = MaxPooling2D(pool_size=(2, 2))(main)\n",
        "\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (2,2), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "\n",
        "    ######Inception module A#####\n",
        "    main = inception_A(main)\n",
        "    main = inception_A(main)\n",
        "    main = inception_A(main)\n",
        "\n",
        "    ######Inception module B#####\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "\n",
        "    ######Inception module C#####\n",
        "    main = inception_C(main)\n",
        "    main = inception_C(main)\n",
        "\n",
        "    main = AveragePooling2D(pool_size=(3, 3))(main)\n",
        "\n",
        "    main = Flatten()(main)\n",
        "    dense = Dense(10, activation='linear')(main)\n",
        "    output = Dense(num_of_classes, activation='softmax')(dense)\n",
        "    return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSSXWoHpwfuM"
      },
      "source": [
        "def inception_A(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll2 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  \n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "\n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "  \n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = keras.layers.concatenate([pll1, pll2, pll3, pll4], axis=3)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4jeNWSBwhL0"
      },
      "source": [
        "def inception_B(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input) \n",
        "  pll2 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  pll2 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll2)\n",
        "\n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  \n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "\n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = keras.layers.concatenate([pll1, pll2, pll3, pll4], axis = 3)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbmxzFBPwis1"
      },
      "source": [
        "def inception_C(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll1_a = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1_b = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  \n",
        "  pll2_a = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  pll2_b = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll2)\n",
        "\n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "\n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = concatenate([pll1_a, pll1_b, pll2_a, pll2_b, pll3, pll4], axis=3)\n",
        "  return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0i4lTaNwkKQ"
      },
      "source": [
        "#Definition of SGD optimizer\n",
        "adam = optimizers.Adam(learning_rate=l_rate)#, decay=lr_decay,momentum=0.9, nesterov=True)\n",
        "\n",
        "input = Input(shape=(32, 32, 3))\n",
        "output = inceptionv2(input)\n",
        "\n",
        "model = Model([input], output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ3qsJ29wl1J"
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXe0CGq0wnTN",
        "outputId": "fa9c336a-2556-4127-b0ab-633440ef6ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "#Defintion of callbacks with EarlyStopping \n",
        "callback = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "#Definition of saving the best weights of the model with ModelCheckpoint\n",
        "checkpoint_path = \"checkpoints\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1, mode='min')\n",
        "\n",
        "#Training the model in the training dataset\n",
        "history = model.fit(x_train, y_train, epochs = maxepoches, batch_size = batch_size, validation_data=(x_validation, y_validation), callbacks=[callback, checkpoint])\n",
        "model.save_weights('InceptionV2_ADAM_NoRegularization.h5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " 41/313 [==>...........................] - ETA: 5:47 - loss: 4.6133 - accuracy: 0.0093"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-dcf6963aeb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Training the model in the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaxepoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'InceptionV2_ADAM_NoRegularization.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8MrlOUswpC8"
      },
      "source": [
        "#Plot the Training and Validation accuracy v/s Epochs\n",
        "#history.keys() = ['accuracy', 'loss', 'val_accuracy', 'val_loss']\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3cafraDwq6z"
      },
      "source": [
        "#Plot the Training and Validation loss v/s Epochs\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sae7khguwsnO"
      },
      "source": [
        "#Testing the model using the best weights of the model\n",
        "\n",
        "model.load_weights('./InceptionV2_ADAM_NoRegularization.h5')\n",
        "loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "predict_y_test_o = model.predict(x_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "warx8QUowuD2"
      },
      "source": [
        "# #Precision, recall and accuracy of the model on test data\n",
        "predict_y_test = np.argmax(predict_y_test_o, axis=1)\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test_o, predict_y_test)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test_o, predict_y_test, average='macro')\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test_o, predict_y_test, average='macro')\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_matrix_ = confusion_matrix(y_test_o, predict_y_test)\n",
        "print(confusion_matrix_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvQ2XGllwwTS"
      },
      "source": [
        "import seaborn as sb\n",
        "heat_map = sb.heatmap(confusion_matrix_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}