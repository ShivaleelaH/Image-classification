{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV2_ADAM_DropOut.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF2uPPe9z3jo"
      },
      "source": [
        "*   Network     : Inception v2\n",
        "*   Optimizer   : ADAM\n",
        "*   Regularizer : Dropout\n",
        "\n",
        "Ref for code: https://arxiv.org/pdf/1512.00567v3.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhAE4ebAz31c"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras import callbacks\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.datasets import cifar100\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, concatenate, Dropout\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import layer_utils, data_utils, vis_utils, plot_model #data_utils.get_file #vis_utils.model_to_dot\n",
        "\n",
        "import numpy as np\n",
        "import pydot\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from IPython.display import SVG\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5kuQ9Eaz45Q"
      },
      "source": [
        "#Loading cifar100 dataset and dividing into Train, Validation and Test sets\n",
        "\n",
        "(X_train, Y_train), (x_test, y_test_o) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 100)\n",
        "y_validation = keras.utils.to_categorical(y_validation, 100)\n",
        "y_test = keras.utils.to_categorical(y_test_o, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEC-GE0Ez44e"
      },
      "source": [
        "weight_decay = 0.0005\n",
        "num_of_classes = 100\n",
        "conv_activation_func = 'elu'\n",
        "\n",
        "l_rate = 0.0001\n",
        "batch_size = 128\n",
        "maxepoches = 40\n",
        "lr_decay = 1e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As5ncfomz41g"
      },
      "source": [
        "def inceptionv2(input):\n",
        "    model = Sequential()\n",
        "\n",
        "    ##### MAIN LAYER #####\n",
        "    main = Conv2D(64, (3, 3), strides=(2,2), padding='same',activation=conv_activation_func)(input)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "\n",
        "    main = MaxPooling2D(pool_size=(2, 2))(main)\n",
        "\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (2,2), padding='same', activation=conv_activation_func)(main)\n",
        "    main = Conv2D(64, (3, 3), strides = (1,1), padding='same', activation=conv_activation_func)(main)\n",
        "\n",
        "    ######Inception module A#####\n",
        "    main = inception_A(main)\n",
        "    main = inception_A(main)\n",
        "    main = inception_A(main)\n",
        "\n",
        "    ######Inception module B#####\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "    main = inception_B(main)\n",
        "\n",
        "    ######Inception module C#####\n",
        "    main = inception_C(main)\n",
        "    main = inception_C(main)\n",
        "\n",
        "    main = AveragePooling2D(pool_size=(3, 3))(main)\n",
        "\n",
        "    main = Flatten()(main)\n",
        "    dense = Dense(10, activation='linear')(main)\n",
        "    dense = Dropout(0.2)(dense)\n",
        "    output = Dense(num_of_classes, activation='softmax')(dense)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ivfhWDez4yk"
      },
      "source": [
        "def inception_A(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll2 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  \n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "\n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "  \n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = keras.layers.concatenate([pll1, pll2, pll3, pll4], axis=3)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRYuvTtIz4uh"
      },
      "source": [
        "def inception_B(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input) \n",
        "  pll2 = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  pll2 = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll2)\n",
        "\n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  \n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "\n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = keras.layers.concatenate([pll1, pll2, pll3, pll4], axis = 3)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yho-oevzz4sY"
      },
      "source": [
        "def inception_C(input):\n",
        "  pll1 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  pll1 = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll1_a = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll1)\n",
        "  pll1_b = Conv2D(64, (3,3), padding='same', activation=conv_activation_func)(pll1)\n",
        "\n",
        "  pll2 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "  \n",
        "  pll2_a = Conv2D(64, (1,3), padding='same', activation=conv_activation_func)(pll2)\n",
        "  pll2_b = Conv2D(64, (3,1), padding='same', activation=conv_activation_func)(pll2)\n",
        "\n",
        "  pll3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  pll3 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(pll3)\n",
        "\n",
        "  pll4 = Conv2D(64, (1,1), padding='same', activation=conv_activation_func)(input)\n",
        "\n",
        "  output = concatenate([pll1_a, pll1_b, pll2_a, pll2_b, pll3, pll4], axis=3)\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40QfwtIgz4qN"
      },
      "source": [
        "#Definition of SGD optimizer\n",
        "adam = optimizers.Adam(learning_rate=l_rate)#, decay=lr_decay,momentum=0.9, nesterov=True)\n",
        "\n",
        "input = Input(shape=(32, 32, 3))\n",
        "output = inceptionv2(input)\n",
        "\n",
        "model = Model([input], output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ6Jhp1nz4oF"
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "# (std, mean, and principal components if ZCA whitening is applied).\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WSteIlbz4nU"
      },
      "source": [
        "#Defintion of callbacks with EarlyStopping \n",
        "callback = callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "#Definition of saving the best weights of the model with ModelCheckpoint\n",
        "checkpoint_path = \"checkpoints\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1, mode='min')\n",
        "\n",
        "#Training the model in the training dataset\n",
        "history = model.fit(x_train, y_train, epochs = maxepoches, batch_size = batch_size, validation_data=(x_validation, y_validation), callbacks=[callback, checkpoint])\n",
        "model.save_weights('InceptionV2_ADAM_DropOut.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVKhMO15z4il"
      },
      "source": [
        "#Plot the Training and Validation accuracy v/s Epochs\n",
        "#history.keys() = ['accuracy', 'loss', 'val_accuracy', 'val_loss']\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hnWYiNz4fR"
      },
      "source": [
        "#Plot the Training and Validation loss v/s Epochs\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUgcPWaLz4cG"
      },
      "source": [
        "#Testing the model using the best weights of the model\n",
        "\n",
        "model.load_weights('./InceptionV2_ADAM_DropOut.h5')\n",
        "loss, acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "predict_y_test_o = model.predict(x_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp00DMXzz4Zf"
      },
      "source": [
        "# #Precision, recall and accuracy of the model on test data\n",
        "predict_y_test = np.argmax(predict_y_test_o, axis=1)\n",
        "\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test_o, predict_y_test)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test_o, predict_y_test, average='macro')\n",
        "print('Precision: %f' % precision)\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test_o, predict_y_test, average='macro')\n",
        "print('Recall: %f' % recall)\n",
        "\n",
        "# Confusion matrix\n",
        "confusion_matrix_ = confusion_matrix(y_test_o, predict_y_test)\n",
        "print(confusion_matrix_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQZKUFYz4Wp"
      },
      "source": [
        "import seaborn as sb\n",
        "heat_map = sb.heatmap(confusion_matrix_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY8tn1cNz4RU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}